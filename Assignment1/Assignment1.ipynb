{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Perform tokenization (Whitespace, Punctuation-based, Treebank, Tweet, MWE) using NLTK library. Use porter stemmer and snowball stemmer for stemming. Use any technique for lemmatization.  "
      ],
      "metadata": {
        "id": "sYauU81sVin0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import (\n",
        "    WhitespaceTokenizer,\n",
        "    word_tokenize,\n",
        "    sent_tokenize,\n",
        "    TreebankWordTokenizer,\n",
        "    TweetTokenizer,\n",
        "    MWETokenizer\n",
        ")\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "NTV2roSCPO7y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzXfdke7PXTR",
        "outputId": "869c66c4-e404-47e5-af00-1148992cfe42"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"NLTK is great! I'm loving #NLP with Python :) It helps in text processing, tokenization, and language analysis.\n",
        " Learning NLP is fun and useful for real-world applications. New York is a big city,\n",
        " and many developers use Python there for data science and machine learning. Students practice NLP techniques in classrooms and online courses.\n",
        " Social media text, tweets, and comments contain emojis, hashtags, and informal language. Treebank and Tweet tokenizers handle such text efficiently.\n",
        "Stemming reduces words to their root forms, while lemmatization provides meaningful base words.\n",
        "These text preprocessing steps improve the performance of natural language models.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "uJwzSE10QBxw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenization\n"
      ],
      "metadata": {
        "id": "toTO7dl5Puf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#whitespace\n",
        "wt = WhitespaceTokenizer()\n",
        "wt_tokens=wt.tokenize(text)\n",
        "print(wt_tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtt_him1QKzQ",
        "outputId": "2ad3b16f-5d34-4557-ec25-a7253da280be"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'is', 'great!', \"I'm\", 'loving', '#NLP', 'with', 'Python', ':)', 'It', 'helps', 'in', 'text', 'processing,', 'tokenization,', 'and', 'language', 'analysis.', 'Learning', 'NLP', 'is', 'fun', 'and', 'useful', 'for', 'real-world', 'applications.', 'New', 'York', 'is', 'a', 'big', 'city,', 'and', 'many', 'developers', 'use', 'Python', 'there', 'for', 'data', 'science', 'and', 'machine', 'learning.', 'Students', 'practice', 'NLP', 'techniques', 'in', 'classrooms', 'and', 'online', 'courses.', 'Social', 'media', 'text,', 'tweets,', 'and', 'comments', 'contain', 'emojis,', 'hashtags,', 'and', 'informal', 'language.', 'Treebank', 'and', 'Tweet', 'tokenizers', 'handle', 'such', 'text', 'efficiently.', 'Stemming', 'reduces', 'words', 'to', 'their', 'root', 'forms,', 'while', 'lemmatization', 'provides', 'meaningful', 'base', 'words.', 'These', 'text', 'preprocessing', 'steps', 'improve', 'the', 'performance', 'of', 'natural', 'language', 'models.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#punctuation-based\n",
        "tokens_word = word_tokenize(text)\n",
        "print(tokens_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpx9rkrmQUTI",
        "outputId": "130e85e7-745b-49fc-812b-55b7764f172d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'is', 'great', '!', 'I', \"'m\", 'loving', '#', 'NLP', 'with', 'Python', ':', ')', 'It', 'helps', 'in', 'text', 'processing', ',', 'tokenization', ',', 'and', 'language', 'analysis', '.', 'Learning', 'NLP', 'is', 'fun', 'and', 'useful', 'for', 'real-world', 'applications', '.', 'New', 'York', 'is', 'a', 'big', 'city', ',', 'and', 'many', 'developers', 'use', 'Python', 'there', 'for', 'data', 'science', 'and', 'machine', 'learning', '.', 'Students', 'practice', 'NLP', 'techniques', 'in', 'classrooms', 'and', 'online', 'courses', '.', 'Social', 'media', 'text', ',', 'tweets', ',', 'and', 'comments', 'contain', 'emojis', ',', 'hashtags', ',', 'and', 'informal', 'language', '.', 'Treebank', 'and', 'Tweet', 'tokenizers', 'handle', 'such', 'text', 'efficiently', '.', 'Stemming', 'reduces', 'words', 'to', 'their', 'root', 'forms', ',', 'while', 'lemmatization', 'provides', 'meaningful', 'base', 'words', '.', 'These', 'text', 'preprocessing', 'steps', 'improve', 'the', 'performance', 'of', 'natural', 'language', 'models', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#treebank\n",
        "tbt = TreebankWordTokenizer()\n",
        "tbt_tokens = tbt.tokenize(text)\n",
        "print(tbt_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7k0IQd9Qert",
        "outputId": "4ae76cd8-d77b-4953-d206-374152e8bfbc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'is', 'great', '!', 'I', \"'m\", 'loving', '#', 'NLP', 'with', 'Python', ':', ')', 'It', 'helps', 'in', 'text', 'processing', ',', 'tokenization', ',', 'and', 'language', 'analysis.', 'Learning', 'NLP', 'is', 'fun', 'and', 'useful', 'for', 'real-world', 'applications.', 'New', 'York', 'is', 'a', 'big', 'city', ',', 'and', 'many', 'developers', 'use', 'Python', 'there', 'for', 'data', 'science', 'and', 'machine', 'learning.', 'Students', 'practice', 'NLP', 'techniques', 'in', 'classrooms', 'and', 'online', 'courses.', 'Social', 'media', 'text', ',', 'tweets', ',', 'and', 'comments', 'contain', 'emojis', ',', 'hashtags', ',', 'and', 'informal', 'language.', 'Treebank', 'and', 'Tweet', 'tokenizers', 'handle', 'such', 'text', 'efficiently.', 'Stemming', 'reduces', 'words', 'to', 'their', 'root', 'forms', ',', 'while', 'lemmatization', 'provides', 'meaningful', 'base', 'words.', 'These', 'text', 'preprocessing', 'steps', 'improve', 'the', 'performance', 'of', 'natural', 'language', 'models', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tweet tokenization\n",
        "tweet_tokenize = TweetTokenizer()\n",
        "tweet_tokens = tweet_tokenize.tokenize(text)\n",
        "print(tweet_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RJsfSvsRkDJ",
        "outputId": "67299af8-1346-49a3-dcd9-a7cb76e143c3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'is', 'great', '!', \"I'm\", 'loving', '#NLP', 'with', 'Python', ':)', 'It', 'helps', 'in', 'text', 'processing', ',', 'tokenization', ',', 'and', 'language', 'analysis', '.', 'Learning', 'NLP', 'is', 'fun', 'and', 'useful', 'for', 'real-world', 'applications', '.', 'New', 'York', 'is', 'a', 'big', 'city', ',', 'and', 'many', 'developers', 'use', 'Python', 'there', 'for', 'data', 'science', 'and', 'machine', 'learning', '.', 'Students', 'practice', 'NLP', 'techniques', 'in', 'classrooms', 'and', 'online', 'courses', '.', 'Social', 'media', 'text', ',', 'tweets', ',', 'and', 'comments', 'contain', 'emojis', ',', 'hashtags', ',', 'and', 'informal', 'language', '.', 'Treebank', 'and', 'Tweet', 'tokenizers', 'handle', 'such', 'text', 'efficiently', '.', 'Stemming', 'reduces', 'words', 'to', 'their', 'root', 'forms', ',', 'while', 'lemmatization', 'provides', 'meaningful', 'base', 'words', '.', 'These', 'text', 'preprocessing', 'steps', 'improve', 'the', 'performance', 'of', 'natural', 'language', 'models', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Multi-word expression\n",
        "mew_tokenizer = MWETokenizer([('New','York')],separator='_')\n",
        "\n",
        "tokens_mwe = mew_tokenizer.tokenize(text.split())\n",
        "print(tokens_mwe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9mymI70Rtjp",
        "outputId": "0cafbfe4-b4e0-4c6e-ffd8-dd927efaa87d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'is', 'great!', \"I'm\", 'loving', '#NLP', 'with', 'Python', ':)', 'It', 'helps', 'in', 'text', 'processing,', 'tokenization,', 'and', 'language', 'analysis.', 'Learning', 'NLP', 'is', 'fun', 'and', 'useful', 'for', 'real-world', 'applications.', 'New_York', 'is', 'a', 'big', 'city,', 'and', 'many', 'developers', 'use', 'Python', 'there', 'for', 'data', 'science', 'and', 'machine', 'learning.', 'Students', 'practice', 'NLP', 'techniques', 'in', 'classrooms', 'and', 'online', 'courses.', 'Social', 'media', 'text,', 'tweets,', 'and', 'comments', 'contain', 'emojis,', 'hashtags,', 'and', 'informal', 'language.', 'Treebank', 'and', 'Tweet', 'tokenizers', 'handle', 'such', 'text', 'efficiently.', 'Stemming', 'reduces', 'words', 'to', 'their', 'root', 'forms,', 'while', 'lemmatization', 'provides', 'meaningful', 'base', 'words.', 'These', 'text', 'preprocessing', 'steps', 'improve', 'the', 'performance', 'of', 'natural', 'language', 'models.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming\n"
      ],
      "metadata": {
        "id": "3_3-p0pRSM0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#porter stemming\n",
        "porter = PorterStemmer()\n",
        "porter_stemmed = [porter.stem(word) for word in tokens_word]\n",
        "print(porter_stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffjlY_VhTgxX",
        "outputId": "ca38719e-afa5-4fcc-e9c5-9053e215cb32"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nltk', 'is', 'great', '!', 'i', \"'m\", 'love', '#', 'nlp', 'with', 'python', ':', ')', 'it', 'help', 'in', 'text', 'process', ',', 'token', ',', 'and', 'languag', 'analysi', '.', 'learn', 'nlp', 'is', 'fun', 'and', 'use', 'for', 'real-world', 'applic', '.', 'new', 'york', 'is', 'a', 'big', 'citi', ',', 'and', 'mani', 'develop', 'use', 'python', 'there', 'for', 'data', 'scienc', 'and', 'machin', 'learn', '.', 'student', 'practic', 'nlp', 'techniqu', 'in', 'classroom', 'and', 'onlin', 'cours', '.', 'social', 'media', 'text', ',', 'tweet', ',', 'and', 'comment', 'contain', 'emoji', ',', 'hashtag', ',', 'and', 'inform', 'languag', '.', 'treebank', 'and', 'tweet', 'token', 'handl', 'such', 'text', 'effici', '.', 'stem', 'reduc', 'word', 'to', 'their', 'root', 'form', ',', 'while', 'lemmat', 'provid', 'meaning', 'base', 'word', '.', 'these', 'text', 'preprocess', 'step', 'improv', 'the', 'perform', 'of', 'natur', 'languag', 'model', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#snowball stemmer\n",
        "snowball = SnowballStemmer('english')\n",
        "snowball_stemmed = [snowball.stem(word) for word in tokens_word]\n",
        "print(snowball_stemmed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6a9u6xMTt87",
        "outputId": "3229d636-7a88-4014-c584-063bb8c90ac9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['nltk', 'is', 'great', '!', 'i', \"'m\", 'love', '#', 'nlp', 'with', 'python', ':', ')', 'it', 'help', 'in', 'text', 'process', ',', 'token', ',', 'and', 'languag', 'analysi', '.', 'learn', 'nlp', 'is', 'fun', 'and', 'use', 'for', 'real-world', 'applic', '.', 'new', 'york', 'is', 'a', 'big', 'citi', ',', 'and', 'mani', 'develop', 'use', 'python', 'there', 'for', 'data', 'scienc', 'and', 'machin', 'learn', '.', 'student', 'practic', 'nlp', 'techniqu', 'in', 'classroom', 'and', 'onlin', 'cours', '.', 'social', 'media', 'text', ',', 'tweet', ',', 'and', 'comment', 'contain', 'emoji', ',', 'hashtag', ',', 'and', 'inform', 'languag', '.', 'treebank', 'and', 'tweet', 'token', 'handl', 'such', 'text', 'effici', '.', 'stem', 'reduc', 'word', 'to', 'their', 'root', 'form', ',', 'while', 'lemmat', 'provid', 'meaning', 'base', 'word', '.', 'these', 'text', 'preprocess', 'step', 'improv', 'the', 'perform', 'of', 'natur', 'languag', 'model', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n"
      ],
      "metadata": {
        "id": "3UrjOtvnTyYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#wordnetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokens_word]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfvwKOmST9pE",
        "outputId": "4aeca283-0561-49eb-c441-9a13c698df47"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'is', 'great', '!', 'I', \"'m\", 'loving', '#', 'NLP', 'with', 'Python', ':', ')', 'It', 'help', 'in', 'text', 'processing', ',', 'tokenization', ',', 'and', 'language', 'analysis', '.', 'Learning', 'NLP', 'is', 'fun', 'and', 'useful', 'for', 'real-world', 'application', '.', 'New', 'York', 'is', 'a', 'big', 'city', ',', 'and', 'many', 'developer', 'use', 'Python', 'there', 'for', 'data', 'science', 'and', 'machine', 'learning', '.', 'Students', 'practice', 'NLP', 'technique', 'in', 'classroom', 'and', 'online', 'course', '.', 'Social', 'medium', 'text', ',', 'tweet', ',', 'and', 'comment', 'contain', 'emojis', ',', 'hashtags', ',', 'and', 'informal', 'language', '.', 'Treebank', 'and', 'Tweet', 'tokenizers', 'handle', 'such', 'text', 'efficiently', '.', 'Stemming', 'reduces', 'word', 'to', 'their', 'root', 'form', ',', 'while', 'lemmatization', 'provides', 'meaningful', 'base', 'word', '.', 'These', 'text', 'preprocessing', 'step', 'improve', 'the', 'performance', 'of', 'natural', 'language', 'model', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCH4T7I5UEBl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}